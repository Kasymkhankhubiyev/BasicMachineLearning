{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQg6-zTVaM2i"
      },
      "outputs": [],
      "source": [
        "pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryZ-R_7zMk_X"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g13aBidAYZBy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ],
      "metadata": {
        "id": "GINElXzAcSPc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Fp4M1i2WU7N9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NoOYHwiRNqc-"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ML 4 course/train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ML 4 course/test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#show dataset"
      ],
      "metadata": {
        "id": "LtAEx7V9I3vJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "hMJGdwI3W6-Y",
        "outputId": "0e7a559f-b00d-43fb-d167-c59c99c97775"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-445558c3-a95e-4c55-ba8d-ec8840d0fd9d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-445558c3-a95e-4c55-ba8d-ec8840d0fd9d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-445558c3-a95e-4c55-ba8d-ec8840d0fd9d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-445558c3-a95e-4c55-ba8d-ec8840d0fd9d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5iErXFFWPka",
        "outputId": "1da278e1-a419-4289-bcc7-15690253225f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
            "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
            "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
            "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
            "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
            "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
            "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
            "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
            "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
            "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
            "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
            "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
            "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
            "       'SaleCondition', 'SalePrice'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(train_data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyJ7BWtjWcqf",
        "outputId": "5ca1d8d1-740d-4150-a197-39788a371464"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pave    1454\n",
              "Grvl       6\n",
              "Name: Street, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_data['Street'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "oHxReVo0Xi0A",
        "outputId": "bf3d8da0-ed58-477c-edc3-f278bfbf44cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
              "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
              "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
              "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
              "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
              "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
              "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
              "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
              "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
              "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
              "\n",
              "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
              "0       0      6    2010        WD         Normal  \n",
              "1   12500      6    2010        WD         Normal  \n",
              "2       0      3    2010        WD         Normal  \n",
              "3       0      6    2010        WD         Normal  \n",
              "4       0      1    2010        WD         Normal  \n",
              "\n",
              "[5 rows x 80 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff6dd61f-8661-427f-9b35-15cf5dfbf75e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>20</td>\n",
              "      <td>RH</td>\n",
              "      <td>80.0</td>\n",
              "      <td>11622</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>81.0</td>\n",
              "      <td>14267</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gar2</td>\n",
              "      <td>12500</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>74.0</td>\n",
              "      <td>13830</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>78.0</td>\n",
              "      <td>9978</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>120</td>\n",
              "      <td>RL</td>\n",
              "      <td>43.0</td>\n",
              "      <td>5005</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>HLS</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>144</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 80 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff6dd61f-8661-427f-9b35-15cf5dfbf75e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff6dd61f-8661-427f-9b35-15cf5dfbf75e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff6dd61f-8661-427f-9b35-15cf5dfbf75e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWGwf-rnYhux"
      },
      "source": [
        "#подготовка датафреймов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e8oF9KyVYl4_"
      },
      "outputs": [],
      "source": [
        "def deleteId(ds):\n",
        "    return ds.drop(columns='Id')\n",
        "\n",
        "def deleteNaN(train_ds, test_ds, critval):\n",
        "    fullsize = train_ds.shape[0]\n",
        "    new_train = train_ds.copy()\n",
        "    new_test = test_ds.copy()\n",
        "    for feature in new_train.columns:\n",
        "        nulls = new_train[feature].isnull().sum()\n",
        "        percent = nulls / fullsize\n",
        "        # если доля пустых значений превышает critval - столбец не информативен,\n",
        "        # можно его выбросить\n",
        "        if (percent > critval):\n",
        "            new_train = new_train.drop(columns=feature)\n",
        "            new_test = new_test.drop(columns=feature)\n",
        "    return new_train, new_test\n",
        "\n",
        "def convertToNumeric(train_ds, test_ds):\n",
        "    new_train = train_ds.copy()\n",
        "    new_test = test_ds.copy()\n",
        "    LE = LabelEncoder()\n",
        "    for feature in new_train.columns[:-1]:\n",
        "        if (new_train[feature].dtype == 'object'):\n",
        "            new_train[feature] = LE.fit_transform(new_train[feature])\n",
        "            new_test[feature] = LE.fit_transform(new_test[feature])\n",
        "    return new_train, new_test\n",
        "\n",
        "train = train_data.drop_duplicates()\n",
        "train = train.drop(columns='Id')\n",
        "test = test_data.drop(columns='Id')\n",
        "\n",
        "train, test = deleteNaN(train, test, critval=0.7)\n",
        "train, test = convertToNumeric(train, test)\n",
        "\n",
        "train_y = train['SalePrice'].values\n",
        "train_X = train.drop(columns='SalePrice').values\n",
        "val_test = test.values\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(train_X, train_y, test_size=0.1, random_state=98987)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Id'].isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pRF_WWL-8mm",
        "outputId": "7e592a8c-f132-4d5c-e7cb-e45a7902cf74"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Заполнение пропусков"
      ],
      "metadata": {
        "id": "3W7CUSY2h93n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2EAmTQGJRGE"
      },
      "source": [
        "Хорошо, но train остались пропущеные значения. Как их заполнить? \n",
        "Есть несколько тсратегий для заполнения пропущенных значений.\n",
        "\n",
        "Заполнять пропущенные значения тем, что понравится на угад - не лучшая стратегия, часто применяют статистику для вычисления более-менее подходящего значения.\n",
        "\n",
        "1. Самый простой и интуитивный способ - заполнить средним арифметическим значением колонки. Это не изменит среднее значение по всем значениям колонки.\n",
        "2. Но иногда попадаются выбросы, поэтому, чтобы сделать вычисление среднего более робастным, можно брать усеченное среднее - сортируем значения в колонке, отбрасываем n штук слева и n штук справа и считаем среднее арифметическое.\n",
        "3. Медианное среднее - медиана это точка ровно по середине выборки - сортируем значения колонки и тыкаем в середку. Такое среднее более устойчиво к выбросам, чем среднее арифметическое.\n",
        "4. Наиболее часто встрчаемое - еще одна стратегия для заполнения - если чаще всего встречается - почему бы и нет."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Когда находим пропуск, можно искать наиболее похожую строку в датасете и заполнить этим значением. Близость можно определить расстоянием в пространстве значений, например евклидово расстояние или косинусное расстояние."
      ],
      "metadata": {
        "id": "uRt-21z-is5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#найдем все колонки с пропущенными данными\n",
        "def find_nan_columns(dataframe):  # возращаем список в виде [название колонки, процент пропущенных значений]\n",
        "    fullsize = dataframe.shape[0]\n",
        "    nan_columns = []\n",
        "    rows_with_nan = []\n",
        "    new_train = dataframe.copy()\n",
        "    for column in dataframe.columns:\n",
        "        nulls = new_train[column].isnull().sum()\n",
        "        if nulls != 0:\n",
        "            nan_columns.append([column, nulls / fullsize * 100])\n",
        "    return nan_columns\n",
        "\n",
        "def fill_data_gaps(dataframe, nan_columns):\n",
        "    _df = dataframe.copy()\n",
        "    for i in range(len(nan_columns)):\n",
        "        # начинаем обучать с колонки с наименьшим кол-вом пропущенных значений\n",
        "\n",
        "        # выбрасываем колонки с пропущенными значениями: \n",
        "        # при этом уже обученные колонки не выбрасываем\n",
        "        if i+1 != len(nan_columns[i:]):\n",
        "            for column in nan_columns[i+1:]:\n",
        "                _df = _df.drop(columns=column[0])\n",
        "\n",
        "        # берем только строки без пропусков\n",
        "        not_nan_df = _df[_df[nan_columns[i][0]].notnull()]\n",
        "        trainY = not_nan_df[nan_columns[i][0]].values\n",
        "        trainX = not_nan_df.drop(columns = nan_columns[i][0]).values\n",
        "        # обучаем регрессор\n",
        "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "        model.fit(trainX, trainY)\n",
        "        # теперь заполним значения\n",
        "        rows = _df[nan_columns[i][0]].isnull()\n",
        "        for i in range(len(rows)):\n",
        "            if rows[i]:\n",
        "                _df.loc[i, nan_columns[i][0]] = model.predict(_df.loc[i].drop(columns=nan_columns[i][0]).values)\n",
        "    return _df\n",
        "\n",
        "       \n",
        "\n",
        "train = train_data.drop_duplicates()\n",
        "train = train.drop(columns='Id')\n",
        "test = test_data.drop(columns='Id')\n",
        "\n",
        "train, test = deleteNaN(train, test, critval=0.7)\n",
        "train, test = convertToNumeric(train, test)\n",
        "\n",
        "nan_columns = find_nan_columns(train)\n",
        "nan_columns.sort(key = lambda x: x[1])\n",
        "\n",
        "fill_data_gaps(train, nan_columns).head()"
      ],
      "metadata": {
        "id": "rTZOT1JfjrVu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [0, 1, 2]\n",
        "print(x[0:])\n",
        "print(x[1:])\n",
        "print(x[2:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8HoHjTML8uD",
        "outputId": "2bf92cab-0add-48eb-cbb0-9d0100b38f50"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2]\n",
            "[1, 2]\n",
            "[2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.Итеративное обучение моделей на непропущенных данных для предсказания пропущенных данных."
      ],
      "metadata": {
        "id": "lky3nNx1L9mc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Например, если у нас 10 колонок, в первой колонке пропущенно x% данных, во второй - у%, в четвертой - с%. Тогда для заполнения пропущенных данных для четвертой колонки возбмем данные из колонок: 3, 5-10, обучим модельку и заполним предсказаниями. для второй - 3-10 колонки и тоже обучим, для первой - 2-10."
      ],
      "metadata": {
        "id": "K8pzpnlmMIYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#найдем все колонки с пропущенными данными\n",
        "def find_nan_columns(dataframe):  # возращаем список в виде [название колонки, процент пропущенных значений]\n",
        "    fullsize = dataframe.shape[0]\n",
        "    nan_columns = []\n",
        "    rows_with_nan = []\n",
        "    new_train = dataframe.copy()\n",
        "    for column in dataframe.columns:\n",
        "        nulls = new_train[column].isnull().sum()\n",
        "        if nulls != 0:\n",
        "            nan_columns.append([column, nulls / fullsize * 100])\n",
        "    return nan_columns\n",
        "\n",
        "def fill_data_gaps(dataframe, nan_columns):\n",
        "    _df = dataframe.copy()\n",
        "    for i in range(len(nan_columns)):\n",
        "        # начинаем обучать с колонки с наименьшим кол-вом пропущенных значений\n",
        "\n",
        "        # выбрасываем колонки с пропущенными значениями: \n",
        "        # при этом уже обученные колонки не выбрасываем\n",
        "        if i != len(nan_columns[i:]):\n",
        "            for column in nan_columns[i+1:]:\n",
        "                _df = _df.drop(columns=column[0])\n",
        "\n",
        "        # берем только строки без пропусков\n",
        "        not_nan_df = _df[_df[nan_columns[i][0]].notnull()]\n",
        "        trainY = not_nan_df[nan_columns[i][0]].values\n",
        "        trainX = not_nan_df.drop(columns = nan_columns[i][0]).values\n",
        "        # обучаем регрессор\n",
        "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "        model.fit(trainX, trainY)\n",
        "        # теперь заполним значения\n",
        "        rows = _df[nan_columns[i][0]].isnull()\n",
        "        for i in range(len(rows)):\n",
        "            if rows[i]:\n",
        "                _df.loc[i, nan_columns[i][0]] = model.predict(_df.loc[i].drop(columns=nan_columns[i][0]).values)\n",
        "    return _df\n",
        "\n",
        "       \n",
        "\n",
        "train = train_data.drop_duplicates()\n",
        "train = train.drop(columns='Id')\n",
        "test = test_data.drop(columns='Id')\n",
        "\n",
        "train, test = deleteNaN(train, test, critval=0.7)\n",
        "train, test = convertToNumeric(train, test)\n",
        "\n",
        "nan_columns = find_nan_columns(train)\n",
        "nan_columns.sort(key = lambda x: x[1])\n",
        "\n",
        "fill_data_gaps(train, nan_columns).head()"
      ],
      "metadata": {
        "id": "KRBJSRgLPr1c"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Стандартный подход"
      ],
      "metadata": {
        "id": "7n1KwfVQjzWi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UohfgsrJArE"
      },
      "outputs": [],
      "source": [
        "strategies = ['mean', 'median', 'most_frequent']\n",
        "imputer = SimpleImputer(strategy=strategies[2])\n",
        "trainX = imputer.fit_transform(train_x)\n",
        "testX = imputer.fit_transform(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zmTZ4pAOe_2"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "trainX = scaler.fit_transform(trainX)\n",
        "testX = scaler.transform(testX)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUkhPo_R0wcH",
        "outputId": "07a9fbc8-1aa6-429b-cf89-1b638824526b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1314, 75)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPTZEjVAQFns"
      },
      "source": [
        "#RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvIWmHBBQH0i"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'criterion':(['squared_error']), \n",
        "    'max_depth':  range(1000, 3001, 500),\n",
        "    'n_estimators': range(10, 51, 10),\n",
        "    'min_samples_leaf': range(1, 9, 2),\n",
        "    'min_samples_split': range(2, 11, 2)}\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "rf_gs_model = GridSearchCV(model, parameters)\n",
        "rf_gs_model.fit(trainX[:600], train_y[:600])\n",
        "print(f\"Best parameters: {rf_gs_model.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRI07uNTVPVy"
      },
      "outputs": [],
      "source": [
        "def check_error(preds, gt):\n",
        "    print('RMSE Error:', mean_squared_error(np.log(preds), np.log(gt), squared=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rroaOFzpQOs9",
        "outputId": "25eff957-1b4c-4b1a-862c-110798ee2f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE Error: 0.15719618143042727\n"
          ]
        }
      ],
      "source": [
        "last_rf_best_params = {\n",
        "    'criterion': 'squared_error', \n",
        "    'max_depth': 1500,\n",
        "    'n_estimators': 40,\n",
        "    'min_samples_leaf': 1,\n",
        "    'min_samples_split': 2\n",
        "}\n",
        "\n",
        "random_forest = RandomForestRegressor(**last_rf_best_params)  # (**rf_gs_model.best_params_)\n",
        "random_forest.fit(trainX, train_y)\n",
        "check_error(random_forest.predict(testX), test_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzb1qUGDcKYj"
      },
      "source": [
        "#XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhckjfHHcT3x"
      },
      "source": [
        "Бустинг - метод ансамблирования, в котором обучается много копий более слабой модели (\"weak learner\"), т.е. такой модели, которая не может достичь высокой точности на обучающей выборке, переобучившись на ней. Например, решающее дерево небольшой глубины. На каждом шаге новая модель концентрируется на исправлении ошибок предыдущей модели. Итоговое предсказание получается как взвешенное голосование всех моделей. Таким образом, главное отличие Бустинга от бэггинга - обучение моделей происходит зависимо от предыдущих моделей и последовательно, когда в бэггинге обучение происходит независимо и параллельно.\n",
        "\n",
        "XGBoost - вычислительно эффективная реализация градиентного бустинга над решающими деревьями.\n",
        "\n",
        "Суть градинетного бустинга в следующем: каждый последующий \"слабый\" алгоритм должен корректировать предсказания предыдущего. При этом входными параметрами следующего алгоритма является минус градиент функции потерь по предсказаниям предыдущего алгоритма. При этом от функции потерь не трубуется дифференцируемость по параметрам в отличе от градиентного спуска, но требуется диференцируемость по предсказаниям."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пусть:\n",
        "- $\\{x_i, y_i\\}_{i=1}^N$ - обучающая выборка\n",
        "- K - кол-во деревьев в ансамбле\n",
        "- $f_k:x \\rightarrow y$ - k-e дерево ансамбля как функция\n",
        "- $F: x → y$ - весь ансамбль как функция\n",
        "- $loss: y_{true} \\times y_{pred} → R$ - какая-то функция потерь\n",
        "- $T_k$ - кол-во листьев в к-ом дереве\n",
        "- $w_k$ - вектор, составленный из выходных значений на всех листьях к-го дерева\n",
        "\n",
        "в XGBoost ответы суммируются по всем деревьям ансамбля: $$F(x) = Σ_{k=1}^Kf_x(x)$$\n",
        "\n",
        "Суммарная функция потерь выглядит так: $$Loss_{total} = Σ_{i=1}^Nloss(y_i, F(x_i)) + γΣ_{k=1}^KT_k + \\frac{1}{2}λΣ_{k=1}^K||w_k||^2,$$\n",
        "где γ, λ - гиперпараметры.\n",
        "\n",
        "Первое слагаемое - суммируем все потери по всем деревьям,\n",
        "\n",
        "Второе слагаемое - штрафует деревья за слишком большое кол-во листьев,\n",
        "\n",
        "Третье слагаемое - обеспечивает механизм, чтобы каждое дерево вносило минимальный вклад в результат.\n",
        "\n",
        "Для минимизации $Loss_{total}$ используются первая и вторая производные по предсказаниями."
      ],
      "metadata": {
        "id": "SZZxIh-Zw5hA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Построение деревьев**\n",
        "\n",
        "Введем целевую функцию (objective function): $$obj = Σ_{i=1}^Nloss(y_i, y_i^{'(t)} + Σ_{i=1}^tw(f_i)) $$\n",
        "\n",
        "Каждое следующее дерево должно улучшать предсказание предыдущего:\n",
        "$$y_i^{'(t+1)} = y_i^{'(t)} + f_{t+1}(x_i)$$\n",
        "\n",
        "Вопрос: как строить дерево на каждой следующей итерации? Интуитивный ответ - строить так, чтобы оптимизировать целевую функцию:\n",
        "\n",
        "$obj^{(t)} = Σ_{i=1}^Nloss(y_i, y_i^{'(t)}) + Σ_{i=1}^tw(f_i) = Σ_{i=1}^Nloss(y_i, y_i^{'(t-1)} + f_t(x_i)) + Σ_{i=1}^tw(f_i) + constant$\n",
        "\n",
        "если, например, использовать MSE:\n",
        "\n",
        "$obj^{(t)} = Σ_{i=1}^N(y_i - ( y_i^{'(t-1)} + f_t(x_i)))^2 + Σ_{i=1}^tw(f_i) = Σ_{i=1}^N[(y_i - y_i^{'(t-1)})^2 + 2(y_i - y_i^{'(t-1)})f_t(x_i) + f_t(x_i)^2] + Σ_{i=1}^tw(f_i) + constant$\n",
        "\n",
        "в случае MSE получается полегче т.к. сама функция квадратичная, а основание \n",
        "линейное. В случае других функций потерь пользуемся разложением в ряд Тейлора.\n",
        "\n",
        "$obj^{(t)} = Σ_{i=1}^N[loss(y_i, y_i^{'(t-1)}) + g_if_t(x_i) + \\frac{1}{2}h_if_t^2(x_i)] + w(f_t) + const$, где:\n",
        "\n",
        "$$g_i = \\frac{dloss(y_i, y_i^{'(t-1)})}{dy_i^{'(t-1)}}$$\n",
        "$$h_i = \\frac{d^2loss(y_i, y_i^{'(t-1)})}{d(y_i^{'(t-1)})^2}$$\n",
        "\n",
        "После приведения всех слогаемых, получаем оптимизационную задачу для построения нового дерева:\n",
        "\n",
        "$$Σ_{i=1}^N[g_if_t(x_i)+\\frac{1}{2}h_if_t^2(x_i)] + w(f_t)$$\n",
        "\n",
        "Сложность будем определять следующим образом:\n",
        "\n",
        "$$w(f) = γT + \\frac{1}{2}λΣ_{j=1}^Tw_j^2$$, где w - вектор значений листьев, T - кол-во листьев\n",
        "\n",
        "Тогда с учетом вышеуказанной регуляризации перепишем нашу целевую функцию:\n",
        "\n",
        "$$obj^{(t)} = Σ_{i=1}^N[g_if_t(x_i)+\\frac{1}{2}h_if_t^2(x_i)] + γT + \\frac{1}{2}λΣ_{j=1}^Tw_j^2 = Σ_{j=1}^T[(Σ_{i из I_j}g_i)w_i + \\frac{1}{2}(Σ_{i из I_j}h_i + λ)w_j^2] + γT$$, где $I_j = \\{i|q(x_i)=j\\}$ - множество элементов выборки, относящихся к j-ому листу.\n",
        "\n",
        "\n",
        "положим $G_i =Σ_{i из I_j}g_i $ и $H_j=Σ_{i из I_j}h_i$, тогда\n",
        "\n",
        "$$obj^{(t)} = Σ_{j=1}^T[G_jw_j + 1/2(H_j + λ)w_j^2] + γT$$ - получили функцию, которая квадратично зависит от $w_j$ - поэтому можем легко найти наилучшую оценку:\n",
        "\n",
        "$$w_j^* = -\\frac{G_j}{H_j + λ}$$\n",
        "$$obj^* = -\\frac{1}{2}Σ_{j=1}^T\\frac{G_i^2}{H_j+λ}+γT$$ - измеряет, насколько построенное дерево \"хорошее\"\n",
        "\n",
        "$$IG = \\frac{1}{2}[\\frac{G_L^2}{H_L+λ} + \\frac{G_R^2}{H_R+λ} - \\frac{(G_L + G_R)^2}{H_L+H_R+λ}] - γ$$\n",
        "\n",
        "- первое слагаемое показывает оценку левого листа\n",
        "- второе слагаемое оценку правого листа\n",
        "- третье слагаемое оценка исходного листа\n",
        "- четвертое слагаемое - регуляризация добавленного листа\n",
        "\n",
        "Заметим, если прирост меньше чем регуляризация - мы не будем делить лист на две части."
      ],
      "metadata": {
        "id": "be1Qx8LDA12M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Одним из важных настраиваемых параметров является **subsample** - которые указывает размер подвыборки но без возврата, и learning rate конечно."
      ],
      "metadata": {
        "id": "GYQ2aRy33cI2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d5EJdYqcSQv"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    \"learning_rate\": np.linspace(0.1, 0.5, 10),\n",
        "    \"max_depth\": range(3, 10, 1),\n",
        "    \"min_child_weight\": range(5, 16, 2),\n",
        "    \"n_estimators\": range(30, 91, 10),\n",
        "    \"subsample\": (0.63, 0.7, 0.75, 0.81)\n",
        "}\n",
        "\n",
        "model = XGBRegressor()\n",
        "xgb_gs_model = GridSearchCV(model, parameters)\n",
        "xgb_gs_model.fit(trainX[:600], train_y[:600])\n",
        "print(f\"Best parameters: {xgb_gs_model.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_xgb_best_params = {\n",
        "    \"learning_rate\": 0.15,\n",
        "    \"max_depth\": 3,\n",
        "    \"min_child_weight\": 6,\n",
        "    \"n_estimators\": 50, \n",
        "    \"subsample\": 0.75,\n",
        "    \"booster\": 'gbtree',\n",
        "    # \"reg_lambda\": 1\n",
        "    \"gamma\": 0\n",
        "}\n",
        "\n",
        "xgb_reg = XGBRegressor(**last_xgb_best_params)  #(**xgb_gs_model.best_params_)\n",
        "xgb_reg.fit(trainX, train_y)\n",
        "check_error(xgb_reg.predict(testX), test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFNRVh4l7nIp",
        "outputId": "0acf5845-bd36-4333-bb34-6e032ddaed3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:05:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "RMSE Error: 0.14302138559911587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_reg.predict(val_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrlPIvp8_Jua",
        "outputId": "a6bc893f-7136-44de-a4b6-d539548e82f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([425859.2 , 375549.97, 427963.6 , ..., 421054.1 , 303494.72,\n",
              "       407534.2 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LightGBM"
      ],
      "metadata": {
        "id": "BZ4xdCJw94RW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LightGBM** - фокусируется на примерах бустинга с большими градиентами. Реализация LigthGBM вводит две ключевые идеи: GOSS и EFB.\n",
        "\n",
        "1. GOSS - градиентная односторонняя выборка - фокусируется на тех учебных примерах, которые приводят к большему градиенту, ускоряя обучения и уменьшая вычислительную сложность алгоритма. Т.е. мы просто используем элементы выборки с наибольшим градиентом, ведь они имеют наибольшее значение для IG.\n",
        "2. EFB - объединение взаимоисключающих признаков - подход объединения разрезженных взаимоисключающих признаков.\n",
        "\n",
        "LightGBM создает деревья решений, которые растут по листам, что означает, что при заданом условии разделяется только один лист."
      ],
      "metadata": {
        "id": "KVX7LjhYg-UZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"learning_rate\": [0.2, 0.1, 0.01],\n",
        "    \"num_leaves\": range(3, 10, 2),\n",
        "    \"max_depth\": range(3, 10 ,2),\n",
        "    \"min_data_in_leaf\": range(5, 100, 5),\n",
        "    \"n_estimators\": range(30, 91, 10)\n",
        "}\n",
        "\n",
        "model = LGBMRegressor()\n",
        "gs_model = GridSearchCV(model, params)\n",
        "gs_model.fit(trainX[:300], train_y[:300])\n",
        "print(f'Best params: {gs_model.best_params_}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5iQ9wH7jYS6",
        "outputId": "3f379330-db80-497a-cb80-2c3488cc85aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'learning_rate': 0.1, 'max_depth': 3, 'min_data_in_leaf': 25, 'n_estimators': 60, 'num_leaves': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_lightgbm_best_params = {\n",
        "    \"learning_rate\": 0.15,\n",
        "    \"num_leaves\": 6,\n",
        "    \"max_depth\": 3,\n",
        "    \"min_data_in_leaf\": 25,\n",
        "    \"n_estimators\": 70\n",
        "}\n",
        "\n",
        "model = LGBMRegressor(**last_lightgbm_best_params)  # (**gs_model.best_params_, eval_metric='rmse')\n",
        "model.fit(trainX, train_y)\n",
        "check_error(model.predict(testX), test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3B-g-Z4kSkj",
        "outputId": "be075173-3572-421e-9e44-53359f8fd0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE Error: 0.1469000875271349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CatBoost"
      ],
      "metadata": {
        "id": "vUDdjHEi9--C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CatBoost - реализация градиентного бустинга над решающими деревьями.\n",
        "\n",
        "Основные особенности:\n",
        "- Использование решающих таблиц\n",
        "- Упорядоченное target-кодирование на категориальных признаках высокой размерности\n",
        "- Бустинг с упорядочиванием обучающих примеров\n",
        "\n",
        "*target-кодирование* - это когда мы вместо категориального признака ставим некоторое статистически оцененное значение целевого признака, например, вместо марки машины - среднюю цену всех авто.\n",
        "\n",
        "Обозначим две проблемы:\n",
        "1. Переобучение (смещенность) в градиентах: т.к. каждый следующий алгоритм обучается на градиенте, в котором уже спрятано целевое значение. - Хочется как-то делать обучение на разных данных, но как? - Для получения несмещенных оценок на объекте $x_i$ храним и достраиваем ансамбль только на выборке без этого объекта - похоже на out-of-bag. Но таких выборок может получиться очень много и очень похожих.\n",
        "2. Надо обрабатывать категориальные признаки с большим числом редких значений."
      ],
      "metadata": {
        "id": "uIEec36a-BCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Решающая таблица** - частный случай забывчивого дерева - все решающие правила одного уровня (на одинаковом расстоянии от корня) проверяют один и тот же признак. В CatBoost - на каждом уровне решающего дерева используется не только общий признак, но и общий порог разделения.\n",
        "\n",
        "**Упорядоченный бустинг** - способ решения переобучения на градиентном бустинге.\n",
        "В CatBoost на каждом шаге бустинга обучается одна решающая таблица(дерево), глубина дерева является гиперпараметром. Если глубина N - N признаков и $2^N$ листьев."
      ],
      "metadata": {
        "id": "6UE3COAY-bT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Идея:\n",
        "- градиент $i$-го объекта вычисляем по модели, которая на этом объекте не обучалась.accuracy_score\n",
        "- строим подвыборку удваивающейся длины: $j=1$ длины 1, $j=2$ длины 2, $j=3$ длины 4, $j=4$ длины 8, ..., $j=n$ длины $2^{n-1}$\n",
        "- строим много таких случайных выборок - делаем перестановки - из каждой перестаовки вытаскиваем подвыборку для обучения.\n",
        "\n",
        "Пусть сделаем s случайных перестоновок, r - номер перестановки.\n",
        "\n",
        "тогда для какой-то одной случайной выбраной перестановки рассчитывает градиента: $g_{ti} = Loss^{'}(a_{t-1}^{rj}(x_i), y_i)$ - градиент в точке $(x_i, y_i)$, $j = log_2(i-1)$, t - внутренняя итерация, строим по подвыборке не содержащей этот $x_i$"
      ],
      "metadata": {
        "id": "FjRomj8lOZ58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Алгоритм:**\n",
        " 1. генерируем выборки для всех перестоновок.\n",
        " 2. для всех t = 1, ..., T:\n",
        "  - выбраем выборку построенную с перестоновкой $σ_r$\n",
        "  - вычисляем несмещенный вектор градиента: все элементы одной подвыборки обучаются на алгоритмах не содержащих элементы данной подвыборки:\n",
        "  $$b_t = argmin_b Σ_{i=1}^l(b(x_i) + g_{ti})^2$$ - так мы находим новое дерево - t-ый базовый алгоритм\n",
        "  теперь для всех деревьев $b_t^{ri}$ мы устанавливаем одинаковую структуру дерева - вершины и условия ветвления. Но в каждом дереве вычисляем значения в листьях индивидуально - значения элементов в листбях у каждого дерева свои.\n",
        "  Вычисляем значения в листьях для базового алгоритма на отдельной перестановке выборки и вычисляем как в обычном бустинге вычисляем веса алгоритмов и обновляем алгоритм.\n",
        "\n",
        "- категориальные признаки тоже оцениваются как несмещенная оценка - для $x_i$ элмента выборки категориальный признак оценивается по статистике из элементов $x_j| j < i$"
      ],
      "metadata": {
        "id": "UoUU3DT0lw9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Алгоритм:\n",
        "- На вход подается обучающая выборка, количество шагов, функция потерь, learning rate и количество перестоновок минус единицa s\n",
        "- Сначала создается s+1 перестановка - упорядочивается обучающая выборка.\n",
        "Позицию i-го элемента выборки в перестановке $σ_r$ обозначим как $σ_r(i)$ Эти перестановки применяются как для упорядоченного бустинга, так и для упорядоченного target-кодирования.\n",
        "\n",
        "Catboost на каждом шаге бустинга обучает одно дерево, но при этом иммитирует обучение сразу многих \"виртуальных\" моделей градиентного бустинга. Поэтому результатом на каждом шаге является сразу несоклько предсказаний для каждого примера, результаты хранятся в массиве М. При этом запись $M_{r, j}(i)$ - предсказание на $i$-ом перемере, $r$ - номер перестановки, $j$ - соответствует порядку к упорядоченном бустинге.\n",
        "\n",
        "- при $N$ обчающих элементов, Catboost строит только $log_2n$ моделей.\n",
        "- Каждое новое дерево строится с учетом предыдущих предсказаний"
      ],
      "metadata": {
        "id": "UD2zLd6XD5wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_data.drop_duplicates()\n",
        "train = train.drop(columns='Id')\n",
        "test = test_data.drop(columns='Id')\n",
        "\n",
        "train, test = deleteNaN(train, test, critval=0.7)\n",
        "\n",
        "categorical = []\n",
        "features = train.columns\n",
        "for i in range(len(features)):\n",
        "    if (train[features[i]].dtype == 'object'):\n",
        "        categorical.append(i) \n",
        "\n",
        "train_y = train['SalePrice'].values\n",
        "train_X = train.drop(columns='SalePrice').values\n",
        "val_test = test.values\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(train_X, train_y, test_size=0.1, random_state=98987)\n",
        "\n",
        "imp = SimpleImputer(strategy='most_frequent')\n",
        "trainX = imp.fit_transform(train_x)\n",
        "testX = imp.fit_transform(test_x)"
      ],
      "metadata": {
        "id": "n04rBup71oIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features = {\n",
        "#     \"loss_function\":'RMSE', \n",
        "#     \"cat_features\":categorical,\n",
        "#     \"learning_rate\": [0.3, 0.2, 0.1],\n",
        "#     \"depth\": range(2, 11, 2),\n",
        "#     \"bootstrap_type\":'Bernoulli',\n",
        "#     \"grow_policy\":'SymmetricTree',\n",
        "#     \"l2_leaf_reg\": [0.2, 0.4, 0.6, 0.7]\n",
        "# }\n",
        "\n",
        "# model = CatBoostRegressor()\n",
        "# gs_model = GridSearchCV(model, params)\n",
        "# gs_model.fit(trainX[:300], train_y[:300])\n",
        "# print(f'Best params: {gs_model.best_params_}')"
      ],
      "metadata": {
        "id": "NBPLJ5_rfLQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model = CatBoostRegressor(loss_function='RMSE', \n",
        "                              bagging_temperature=150,\n",
        "                              random_strength=7,\n",
        "                              cat_features=categorical,\n",
        "                              learning_rate=0.075,\n",
        "                              depth=3,\n",
        "                              iterations=1000,\n",
        "                            #   bootstrap_type='Bernoulli',\n",
        "                              grow_policy='SymmetricTree',\n",
        "                              l2_leaf_reg=0.55,\n",
        "                            #   plot=True\n",
        "                              )\n",
        "cat_model.fit(trainX, train_y)\n",
        "check_error(cat_model.predict(testX), test_y)"
      ],
      "metadata": {
        "id": "-S9gTPz9evpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Стэккинг"
      ],
      "metadata": {
        "id": "iw0Q-gWhUH8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что такое стэкинг? Стэкинг - способ ансамблирования моделей, в которой в роли агрегатной функции выступает другой, так называемый, **мета-алгоритм**."
      ],
      "metadata": {
        "id": "O0uP_FsSi05r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StackRegressor:\n",
        "    def __init__(self, params_randomforest=None, params_lightgbm = None, \n",
        "                 params_xgboost=None, params_catboost=None) -> None:\n",
        "\n",
        "        self.model0, self.model1, self.model2, self.model3 = None, None, None, None\n",
        "        self.meta_model = None\n",
        "        self.lr, self.iter = None, None\n",
        "        self.params_randomforest = 0\n",
        "        if params_randomforest is not None:\n",
        "            self.params_randomforest = params_randomforest\n",
        "        self.params_lightgbm = 0\n",
        "        if params_lightgbm is not None:\n",
        "            self.params_lightgbm = params_lightgbm\n",
        "        self.params_xgboost = 0\n",
        "        if params_xgboost is not None:\n",
        "            self.params_xgboost = params_xgboost\n",
        "        self.params_catboost = 0\n",
        "        if params_catboost is not None:\n",
        "            self.params_catboost = params_catboost\n",
        "\n",
        "    def fit(self, trainX, trainY, div) -> None:\n",
        "        trainX0 = trainX[:int(div*len(trainY))]\n",
        "        trainY0 = trainY[:int(div*len(trainY))]\n",
        "        trainX_meta = trainX[int(div*len(trainY)):]\n",
        "        trainY_meta = trainY[int(div*len(trainY)):]\n",
        "\n",
        "        self.model0 = RandomForestRegressor(**self.params_randomforest)\n",
        "        self.model0.fit(trainX0, trainY0)\n",
        "\n",
        "        self.model1 = LGBMRegressor(**self.params_lightgbm, eval_metric='rmse')\n",
        "        self.model1.fit(trainX0, trainY0)\n",
        "\n",
        "        self.model2 = XGBRegressor(**self.params_xgboost)\n",
        "        self.model2.fit(trainX0, trainY0)  \n",
        "\n",
        "        # self.model3 = CatBoostRegressor(loss_function='RMSE', \n",
        "        #                   cat_features=categorical,\n",
        "        #                   learning_rate=0.05,\n",
        "        #                   depth=3,\n",
        "        #                   bootstrap_type='Bernoulli',\n",
        "        #                   grow_policy='SymmetricTree',\n",
        "        #                   l2_leaf_reg=0.25)\n",
        "        # self.model3.fit(trainX0, trainY0)\n",
        "\n",
        "    def predict(self) -> None:\n",
        "        pass"
      ],
      "metadata": {
        "id": "HBNwNxfX93aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_for_gboosting():\n",
        "    train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ML 4 course/train.csv')\n",
        "    test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ML 4 course/test.csv')\n",
        "\n",
        "    train = train_data.drop_duplicates()\n",
        "    train = train.drop(columns='Id')\n",
        "    test = test_data.drop(columns='Id')\n",
        "\n",
        "    train, test = deleteNaN(train, test, critval=0.7)\n",
        "    train, test = convertToNumeric(train, test)\n",
        "\n",
        "    train_y = train['SalePrice'].values\n",
        "    train_X = train.drop(columns='SalePrice').values\n",
        "    val_test = test.values\n",
        "\n",
        "    train_x, test_x, train_y, test_y = train_test_split(train_X, train_y, test_size=0.1, random_state=98987)\n",
        "\n",
        "    strategies = ['mean', 'median', 'most_frequent']\n",
        "    imputer = SimpleImputer(strategy=strategies[2])\n",
        "    trainX = imputer.fit_transform(train_x)\n",
        "    testX = imputer.fit_transform(test_x)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    trainX = scaler.fit_transform(trainX)\n",
        "    testX = scaler.transform(testX)\n",
        "\n",
        "    # return (trainX[int(0.1)*len(train_y):], \n",
        "    #         trainX[:int(0.1)*len(train_y)], \n",
        "    #         train_y[int(0.1)*len(train_y):], \n",
        "    #         train_y[:int(0.1)*len(train_y)], \n",
        "    #         testX[int(0.1)*len(test_y):],\n",
        "    #         testX[:int(0.1)*len(test_y)],\n",
        "    #         test_y[int(0.1)*len(test_y):],\n",
        "    #         test_y[:int(0.1)*len(test_y)])\n",
        "    return trainX, train_y, test_x, test_y\n",
        "\n",
        "\n",
        "def data_for_catboosting():\n",
        "    train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ML 4 course/train.csv')\n",
        "    test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ML 4 course/test.csv')\n",
        "\n",
        "    train = train_data.drop_duplicates()\n",
        "    train = train.drop(columns='Id')\n",
        "    test = test_data.drop(columns='Id')\n",
        "\n",
        "    train, test = deleteNaN(train, test, critval=0.7)\n",
        "\n",
        "    categorical = []\n",
        "    features = train.columns\n",
        "    for i in range(len(features)):\n",
        "        if (train[features[i]].dtype == 'object'):\n",
        "            categorical.append(i) \n",
        "\n",
        "    train_y = train['SalePrice'].values\n",
        "    train_X = train.drop(columns='SalePrice').values\n",
        "    val_test = test.values\n",
        "\n",
        "    train_x, test_x, train_y, test_y = train_test_split(train_X, train_y, test_size=0.1, random_state=98987)\n",
        "\n",
        "    imp = SimpleImputer(strategy='most_frequent')\n",
        "    trainX = imp.fit_transform(train_x)\n",
        "    testX = imp.fit_transform(test_x)\n",
        "\n",
        "    return trainX, train_y, testX, test_y, categorical"
      ],
      "metadata": {
        "id": "TmQIVQ-pV4D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainx_0, test_0, train_y0, test_y0, trainx_1, testx_1, train_y1, test_y1= data_for_gboosting()\n",
        "# cat_trainX0, cat_trainY0, categorical = data_for_catboosting()\n",
        "trainX0, trainy0, trainX1, trainy1 = data_for_gboosting()\n",
        "cat_trainX0, cat_trainy0, cat_trainX1, cat_trainy1, categorical = data_for_catboosting()"
      ],
      "metadata": {
        "id": "E3NYJs0EVQfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestRegressor(**last_rf_best_params)\n",
        "rf_model.fit(trainX0, trainy0)\n",
        "\n",
        "lgbm_model = LGBMRegressor(**last_lightgbm_best_params, eval_metric='rmse')\n",
        "lgbm_model.fit(trainX0, trainy0)\n",
        "\n",
        "xgb_model = XGBRegressor(**last_xgb_best_params)\n",
        "xgb_model.fit(trainX0, trainy0) \n",
        "\n",
        "# cat_model = CatBoostRegressor(loss_function='RMSE', \n",
        "#                               bagging_temperature=150,\n",
        "#                               random_strength=7,\n",
        "#                               cat_features=categorical,\n",
        "#                               learning_rate=0.1,\n",
        "#                               depth=3,\n",
        "#                               iterations=2500,\n",
        "#                             #   bootstrap_type='Bernoulli',\n",
        "#                               grow_policy='SymmetricTree',\n",
        "#                               l2_leaf_reg=0.55)\n",
        "# cat_model.fit(cat_trainX0, cat_trainy1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IZd6_ZDXlIs",
        "outputId": "55ba8538-f7f7-4ad2-a5e0-5eca57c85b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:16:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(learning_rate=0.15, min_child_weight=6, n_estimators=50,\n",
              "             subsample=0.75)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for i in range(len(trainy1)):\n",
        "    predictions.append([rf_model.predict(trainX1[i]), \n",
        "                       lgbm_model.predict(trainX1[i]),\n",
        "                       xgb_model.predict(trainX1[i])])  #, cat_model.predict(cat_trainX1[i])])"
      ],
      "metadata": {
        "id": "JOPoH9kea6mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kaggle"
      ],
      "metadata": {
        "id": "MjMQFNV6AH71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategies = ['mean', 'median', 'most_frequent']\n",
        "imputer = SimpleImputer(strategy=strategies[2])\n",
        "val_test_x = imputer.fit_transform(val_test)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "val_test_x = scaler.fit_transform(val_test_x)"
      ],
      "metadata": {
        "id": "VYV-YJbXAJ0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_path = '/content/drive/MyDrive/Colab Notebooks/ML 4 course/sample_submission.csv'\n",
        "submission = pd.read_csv(submission_path)"
      ],
      "metadata": {
        "id": "TiepIB12ZCV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest.predict(val_test_x)"
      ],
      "metadata": {
        "id": "hrtwlnbxC7Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgboost_predictions = xgb_reg.predict(val_test_x)"
      ],
      "metadata": {
        "id": "B08K2BYdC6pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['SalePrice'] = xgboost_predictions\n",
        "submission\n",
        "submission.to_csv('submission_xgboost.csv', index=False)"
      ],
      "metadata": {
        "id": "hjTEjwuia5qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_data.drop_duplicates()\n",
        "train = train.drop(columns='Id')\n",
        "test = test_data.drop(columns='Id')\n",
        "\n",
        "train, test = deleteNaN(train, test, critval=0.7)\n",
        "\n",
        "categorical = []\n",
        "features = test.columns\n",
        "for i in range(len(features)):\n",
        "    if (test[features[i]].dtype == 'object'):\n",
        "        categorical.append(i) \n",
        "\n",
        "val_test = test.values\n",
        "imp = SimpleImputer(strategy='most_frequent')\n",
        "val_test_x = imp.fit_transform(val_test)\n",
        "# testX = imp.fit_transform(test_x)"
      ],
      "metadata": {
        "id": "DDLamN3rDr83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catboost_predictions = cat_model.predict(val_test_x)"
      ],
      "metadata": {
        "id": "yhP9PqxYEAoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catboost_predictions[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWxNFJ6lGia1",
        "outputId": "be724660-6db5-4ca8-83fa-6e45d7499efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "195791.94291769294"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission['SalePrice'] = catboost_predictions\n",
        "submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "CPkAS_ekZmk5",
        "outputId": "b02fc350-50b0-4481-dc4c-442c3fe62b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Id      SalePrice\n",
              "0     1461  118364.122412\n",
              "1     1462  161312.646421\n",
              "2     1463  197618.872119\n",
              "3     1464  195791.942918\n",
              "4     1465  193338.562441\n",
              "...    ...            ...\n",
              "1454  2915   87136.393590\n",
              "1455  2916   83774.633636\n",
              "1456  2917  155468.490510\n",
              "1457  2918  120404.556310\n",
              "1458  2919  205859.508416\n",
              "\n",
              "[1459 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1ce0110-6e5d-4dc8-a7f3-747ae911bf9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>118364.122412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>161312.646421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>197618.872119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>195791.942918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>193338.562441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1454</th>\n",
              "      <td>2915</td>\n",
              "      <td>87136.393590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>2916</td>\n",
              "      <td>83774.633636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>2917</td>\n",
              "      <td>155468.490510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>2918</td>\n",
              "      <td>120404.556310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>2919</td>\n",
              "      <td>205859.508416</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1459 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1ce0110-6e5d-4dc8-a7f3-747ae911bf9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1ce0110-6e5d-4dc8-a7f3-747ae911bf9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1ce0110-6e5d-4dc8-a7f3-747ae911bf9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('submission_catboost.csv', index=False)"
      ],
      "metadata": {
        "id": "zo6fw2ANaMwH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}